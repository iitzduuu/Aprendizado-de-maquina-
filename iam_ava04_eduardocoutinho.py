# -*- coding: utf-8 -*-
"""IAM_AVA04_eduardocoutinho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s0xatmKF6AsU4xt7xw-wQbskISmvGreu
"""

!pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

spambase = fetch_ucirepo(id=94)


X = spambase.data.features
y = spambase.data.targets

print(spambase.metadata)

print(spambase.variables)

import pandas as pd

data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'

df = pd.read_csv(data_url, header=None, names=column_names)

print(df.columns)

df.head(20)

df.describe()

df['spam'].value_counts()

import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

scaler = MinMaxScaler()

normalized_data = scaler.fit_transform(data)

X = np.random.rand(100, 10)
y = np.random.randint(0, 2, 100)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

model = RandomForestClassifier(random_state=42)
param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=kfold, scoring='accuracy', random_state=42, n_jobs=-1)
random_search.fit(X_scaled, y)

best_model = random_search.best_estimator_

results = cross_val_score(best_model, X_scaled, y, cv=kfold, scoring='accuracy') # avaliação do modelo

print(f"melhores parâmetros: {random_search.best_params_}")
print(f"média de acurácia: {results.mean()}")


param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False],
    'max_leaf_nodes': [50]  # Adicionando a limitação das folhas
}

# continua com a  func randomizedsearchcv e o treinamento
random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=kfold, scoring='accuracy', random_state=42, n_jobs=-1)
random_search.fit(X_scaled, y)


best_tree = random_search.best_estimator_.estimators_[0]

# plotando a arvore com no máximo 50 folhas
plt.figure(figsize=(12, 8))
plot_tree(best_tree, filled=True, feature_names=[f"Feature {i}" for i in range(X_scaled.shape[1])], class_names=['Class 0', 'Class 1'], rounded=True, fontsize=10)
plt.show()

from sklearn.metrics import roc_curve, auc

val_preds = best_model.predict(X_scaled)
fpr, tpr, _ = roc_curve(y, val_preds)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('taxa de falsos positivos')
plt.ylabel('taxa de verdadeiros positivos')
plt.title('receiver operating characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

y_pred = best_model.predict(X_scaled)
cm = confusion_matrix(y, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues')
plt.xlabel('revisões')
plt.ylabel('valores Reais')
plt.title('matriz de Confusão')
plt.show()